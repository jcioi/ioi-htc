#!/usr/bin/env ruby
require 'pathname'
require 'json'
require 'time'
require 'shellwords'

class Config
  def initialize(path)
    @data = File.open(path) {|io| JSON.load(io) }
  end

  def ssh_key
    Pathname(@data.fetch('ssh').fetch('key'))
  end

  def ssh_user
    @data.fetch('ssh').fetch('user')
  end

  def s3_bucket
    @data.fetch('s3').fetch('bucket')
  end

  def s3_prefix
    @data.fetch('s3').fetch('bucket')
  end

  def machines
    @data.fetch('machines')
  end

  def backup_directory
    Pathname('/var/lib/ioi-contestant-backup')
  end

  def state_file
    backup_directory.tap(&:mkpath) + 'state.json'
  end

  def min_interval
    300
  end

  def concurrency
    @data.fetch('concurrency', 1)
  end
end

class Backup
  def initialize(config)
    @config = config
    @lastrun = Hash.new(0)
    @mutex = Thread::Mutex.new

    @state = begin
               open(config.state_file) {|io| JSON.load(io) }
             rescue Errno::ENOENT
               {}
             end
  end

  def run
    machines = config.machines

    batch_size = (machines.size / config.concurrency.to_f).ceil
    machines.each_slice(batch_size) do |machines|
      Thread.new(machines, &method(:worker_loop))
    end

    loop do
      sleep(30)
      write_metrics
    end
  end

  private

  attr_reader :config
  attr_reader :lastrun
  attr_reader :mutex

  def worker_loop(machines)
    loop do
      machines.each(&method(:execute))
    end
  end

  def execute(machine)
    time = Time.now
    date = time.strftime('%F')

    dir = (config.backup_directory + date + machine).tap(&:mkpath)
    prefix = [config.s3_prefix, date, machine].compact.join('/')
    if rsync(machine, dir)
      mutex.synchronize do
        @state['last_successful_rsync'] ||= {}
        @state['last_successful_rsync'][machine] = time.to_i
        File.write(config.state_file, JSON.dump(@state))
      end
    end

    if s3sync(dir, prefix)
      mutex.synchronize do
        @state['last_successful_s3sync'] ||= {}
        @state['last_successful_s3sync'][machine] = time.to_i
        File.write(config.state_file, JSON.dump(@state))
      end
    end
  end

  def write_metrics
    File.open('/var/lib/prometheus-node-exporter/textfile_collector/ioi-contestant-backup.prom', 'w') do |f|
      mutex.synchronize do
        f.puts "# TYPE ioi_contestant_backup_last_successful_rsync_time gauge"
        @state['last_successful_rsync']&.each do |machine, t|
          f.puts %[ioi_contestant_backup_last_successful_rsync_time{machine="#{machine}"} #{t}]
        end

        f.puts "# TYPE ioi_contestant_backup_last_successful_s3sync_time gauge"
        @state['last_successful_s3sync']&.each do |machine, t|
          f.puts %[ioi_contestant_backup_last_successful_s3sync_time{machine="#{machine}"} #{t}]
        end
      end
    end
  end

  def rsync(machine, dir)
    ssh_options = %W[-i #{config.ssh_key} -o User=#{config.ssh_user} -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -o ConnectTimeout=5]

    command = %W[scp] + ssh_options + %W[/usr/share/ioi-contestant-backup/rsync-helper #{machine}:]
    $stderr.puts "! #{command.join(?\s)}"
    system(*command)
    $stderr.puts "#$?: #{command.join(?\s)}"

    rsh = %W[ssh] + ssh_options
    command = %W[rsync -aq -e #{rsh.join(?\s)} --delete --rsync-path="/home/#{config.ssh_user}/rsync-helper" #{machine}:/home/ #{dir}/]
    $stderr.puts "! #{command.join(?\s)}"
    unless system(*command)
      $stderr.puts "#$?: #{command.join(?\s)}"
      return false
    end
    return true
  end

  def s3sync(dir, prefix)
    command = %W[aws s3 sync #{dir}/ s3://#{config.s3_bucket}/#{prefix}/ --delete]
    $stderr.puts "! #{command.join(?\s)}"
    unless system(*command)
      $stderr.puts "#$?: #{command.join(?\s)}"
      return false
    end
    return true
  end
end

Backup.new(Config.new('/etc/ioi-contestant-backup/config.json')).run
